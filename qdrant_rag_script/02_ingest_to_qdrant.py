import os, json, math, hashlib, time, threading, uuid
from pathlib import Path
from typing import List, Dict, Any, Tuple
import orjson
import numpy as np
from tqdm import tqdm
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance, PointStruct
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.node_parser import SentenceSplitter

# ---------------------------
# ì„¤ì •
# ---------------------------
QDRANT_HOST = os.getenv("QDRANT_HOST", "qdrant")  # â† ë¡œì»¬ í…ŒìŠ¤íŠ¸ ê¸°ë³¸ê°’
QDRANT_PORT = int(os.getenv("QDRANT_HTTP_PORT", "6333"))
QDRANT_URL  = f"http://{QDRANT_HOST}:{QDRANT_PORT}"
COLLECTION  = os.getenv("QDRANT_COLLECTION", "peS2o_rag")

EMBED_MODEL    = os.getenv("EMBED_MODEL", "BAAI/bge-m3")  # 1024-d dense
CHUNK_SIZE     = int(os.getenv("CHUNK_SIZE", "1000"))
CHUNK_OVERLAP  = int(os.getenv("CHUNK_OVERLAP", "120"))
BATCH_SIZE     = int(os.getenv("BATCH_SIZE", "512"))
JSON_PATH      = Path(os.getenv("JSON_PATH", "peS2o_sample.jsonl"))
RESUME_FILE    = Path(os.getenv("RESUME_FILE", ".ingest_resume_dualgpu.state"))
VECTOR_DIM     = int(os.getenv("VECTOR_DIM", "1024"))
DISTANCE_ENUM  = Distance.COSINE          # â† ë¬¸ìžì—´ ì•„ë‹˜! Enum ì‚¬ìš©
USE_CACHE      = os.getenv("USE_CACHE", "1") == "1"

# ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ìžˆê³  ë°ì´í„°ê°€ ìžˆëŠ”ë° ìž¬ìƒì„± ë°©ì§€
ALLOW_RECREATE = os.getenv("ALLOW_RECREATE", "0") == "1"

# ---------------------------
# ìœ í‹¸
# ---------------------------
def make_point_id(paper_id: str, chunk_idx: int, text: str) -> str:
    base = f"{paper_id}_{chunk_idx}_{text[:50]}"
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, base))

def iter_jsonl(path: Path, start_idx: int = 0):
    with path.open("r", encoding="utf-8") as f:
        for i, line in enumerate(f):
            if i < start_idx: continue
            s = line.strip()
            if not s: continue
            yield i, orjson.loads(s)

def save_resume(n: int):
    RESUME_FILE.write_text(str(n))

def load_resume() -> int:
    if RESUME_FILE.exists():
        try:
            return int(RESUME_FILE.read_text().strip())
        except:
            return 0
    return 0

# ---------------------------
# Qdrant
# ---------------------------
def ensure_collection(client: QdrantClient):
    exists = False
    try:
        info = client.get_collection(COLLECTION)
        exists = True
        params = info.config.params
        # distance/size ë¶ˆì¼ì¹˜ ì‹œ ê²½ê³ 
        if params.vectors.size != VECTOR_DIM or str(params.vectors.distance).lower().find("cosine") == -1:
            msg = (f"âš ï¸ ì»¬ë ‰ì…˜ ì •ì˜ ë¶ˆì¼ì¹˜: size={params.vectors.size}, "
                   f"distance={params.vectors.distance} (í•„ìš” size={VECTOR_DIM}, distance=Cosine)")
            print(msg)
            if not ALLOW_RECREATE:
                raise RuntimeError(msg + "  (ALLOW_RECREATE=1 í™˜ê²½ë³€ìˆ˜ë¡œ ìž¬ìƒì„± í—ˆìš© ê°€ëŠ¥)")
            print("â™»ï¸  ìž¬ìƒì„± ì§„í–‰ (ë°ì´í„° ì‚­ì œë¨) ...")
            client.recreate_collection(
                collection_name=COLLECTION,
                vectors_config=VectorParams(size=VECTOR_DIM, distance=DISTANCE_ENUM),
            )
            # ìž¬ì‹œìž‘ì´ë¯€ë¡œ resume íŒŒì¼ë„ ì´ˆê¸°í™” ê¶Œìž¥
            if RESUME_FILE.exists():
                RESUME_FILE.unlink(missing_ok=True)
            print(f"âœ… Collection recreated: {COLLECTION} (Cosine/{VECTOR_DIM})")
        else:
            print(f"âœ… Found collection: {COLLECTION} (Cosine/{VECTOR_DIM})")
    except Exception as e:
        if not exists:
            print(f"â„¹ï¸ ì»¬ë ‰ì…˜ ë¯¸ì¡´ìž¬ â†’ ìƒì„±: {COLLECTION}")
            client.recreate_collection(
                collection_name=COLLECTION,
                vectors_config=VectorParams(size=VECTOR_DIM, distance=DISTANCE_ENUM),
            )
            print(f"âœ… Created collection: {COLLECTION} (Cosine/{VECTOR_DIM})")
        else:
            raise

# ---------------------------
# Dual GPU Embedding (ì •ê·œí™” í¬í•¨)
# ---------------------------
class DualGPUEmbedder:
    def __init__(self, model_name: str, batch_size: int = 256):
        # ë‹¨ì¼ GPU í™˜ê²½ì—ì„œë„ ë™ìž‘í•˜ë„ë¡ ê°€ë“œ
        self.models = []
        try:
            self.models.append(HuggingFaceEmbedding(model_name=model_name, device="cuda:0", embed_batch_size=batch_size))
            # ë‘ ë²ˆì§¸ GPUê°€ ì—†ìœ¼ë©´ exceptë¡œ ë„˜ì–´ê°
            self.models.append(HuggingFaceEmbedding(model_name=model_name, device="cuda:1", embed_batch_size=batch_size))
        except Exception:
            # fallback: ë‹¨ì¼ GPU ë˜ëŠ” CPU
            if not self.models:
                self.models.append(HuggingFaceEmbedding(model_name=model_name, device="cuda" if os.getenv("CUDA_VISIBLE_DEVICES") else "cpu", embed_batch_size=batch_size))

        self.cache = {} if USE_CACHE else None

    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        if len(self.models) == 1:
            vecs = self.models[0].get_text_embedding_batch(texts)
        else:
            mid = len(texts) // 2
            parts = [texts[:mid], texts[mid:]]
            res = [None, None]

            def run(idx: int):
                if parts[idx]:
                    res[idx] = self.models[idx].get_text_embedding_batch(parts[idx])

            t1 = threading.Thread(target=run, args=(0,))
            t2 = threading.Thread(target=run, args=(1,))
            t1.start(); t2.start()
            t1.join(); t2.join()

            vecs = []
            for r in res:
                if r: vecs.extend(r)

        # ðŸ”’ Cosine ì¼ê´€ì„± í™•ë³´ë¥¼ ìœ„í•´ í•­ìƒ ë‹¨ìœ„ë²¡í„°í™”
        arr = np.asarray(vecs, dtype=np.float32)
        arr /= np.linalg.norm(arr, axis=1, keepdims=True) + 1e-12
        return arr.tolist()

# ---------------------------
# ì—…ì„œíŠ¸
# ---------------------------
def upsert_batch(client: QdrantClient, ids: List[str], vectors: List[List[float]], payloads: List[Dict[str, Any]]):
    points = [PointStruct(id=ids[i], vector=vectors[i], payload=payloads[i]) for i in range(len(ids))]
    client.upsert(collection_name=COLLECTION, points=points)

# ---------------------------
# ë©”ì¸
# ---------------------------
def main():
    # HTTP ëª¨ë“œ(ì•ˆì •)ë¡œ ì—°ê²°
    client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
    ensure_collection(client)

    # ìž¬ìƒì„±í–ˆìœ¼ë©´ resume ì´ˆê¸°í™” ê¶Œìž¥
    start_line = load_resume()
    print(f"â†©ï¸ Resume from line {start_line}")

    splitter = SentenceSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    embedder = DualGPUEmbedder(EMBED_MODEL, batch_size=256)

    total_chunks = 0
    ids, payloads, texts = [], [], []

    total_lines = sum(1 for _ in open(JSON_PATH, "r", encoding="utf-8"))
    pbar = tqdm(total=total_lines, desc="Ingesting", ncols=100)

    for i, rec in iter_jsonl(JSON_PATH, start_line):
        # ë‹¤ì–‘í•œ ìŠ¤í‚¤ë§ˆ ëŒ€ì‘
        raw_text = (rec.get("text") or rec.get("_node_text") or "").strip()
        if not raw_text:
            pbar.update(1)
            continue

        paper_id = str(rec.get("paper_id") or rec.get("id") or rec.get("doc_id") or "unknown")
        source   = rec.get("source", "peS2o")

        chunks = splitter.split_text(raw_text)
        for ci, chunk in enumerate(chunks):
            pid = make_point_id(paper_id, ci, chunk)
            ids.append(pid)
            payloads.append({"paper_id": paper_id, "source": source, "_node_text": chunk})
            texts.append(chunk)

        # ë°°ì¹˜ ìž„ê³„ ì‹œ ì²˜ë¦¬
        if len(texts) >= BATCH_SIZE:
            vecs = embedder.embed_batch(texts)
            upsert_batch(client, ids, vecs, payloads)
            total_chunks += len(texts)
            ids.clear(); payloads.clear(); texts.clear()
            save_resume(i + 1)
        pbar.update(1)

    # ìž”ì—¬ ì²˜ë¦¬
    if texts:
        vecs = embedder.embed_batch(texts)
        upsert_batch(client, ids, vecs, payloads)
        total_chunks += len(texts)
        save_resume(i + 1)

    print(f"âœ… Done. Total {total_chunks} chunks ingested.")

if __name__ == "__main__":
    main()
