# -*- coding: utf-8 -*-
import logging, nest_asyncio, time, traceback
from fastapi import FastAPI, Request
from fastapi.responses import HTMLResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from starlette.responses import StreamingResponse

from query_pipeline import (
    build_rag_objects_dual,
    triton_infer,
    expand_query_kor,
    dense_retrieve_hybrid,
    rrf_rerank,
    build_context,
    decide_rag_needed,
    tokenizer,
    COLLECTION,
    COLLECTION_B,
)

# ---------------------------
# ì´ˆê¸° ì„¤ì •
# ---------------------------
nest_asyncio.apply()

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger("uvicorn")

app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ì „ì—­ ê°ì²´ (ë©€í‹°ì›Œì»¤ì¼ ë• í”„ë¡œì„¸ìŠ¤ë³„ ì´ˆê¸°í™”)
qdr_a = emb_a = retriever_a = None
qdr_b = emb_b = retriever_b = None


@app.on_event("startup")
async def init_rag():
    global qdr_a, emb_a, retriever_a, qdr_b, emb_b, retriever_b
    logger.info("ğŸš€ Initializing RAG components (dual)...")
    qdr_a, emb_a, retriever_a, qdr_b, emb_b, retriever_b = build_rag_objects_dual()

    # Warmup: GPU/í† í¬ë‚˜ì´ì €/JIT lazy init ë¹„ìš© ì œê±° (A ìŠ¤íƒ ê¸°ì¤€)
    try:
        _ = tokenizer.encode("warmup")
        _ = emb_a.get_text_embedding("warmup")
    except Exception as e:
        logger.info(f"Warmup skipped: {e}")
    logger.info("âœ… RAG pipeline (A/B) ready.\n")


async def triton_stream_async(prompt: str):
    """
    triton_infer(stream=True) ì œë„ˆë ˆì´í„°ë¥¼ ë¹„ë™ê¸° SSEìš©ìœ¼ë¡œ ê°ì‹¸ëŠ” ë˜í¼
    """
    import asyncio

    loop = asyncio.get_event_loop()
    gen = triton_infer(prompt, stream=True)

    i = 0
    while True:
        chunk = await loop.run_in_executor(None, next, gen, None)
        if chunk is None:
            logger.info("[DEBUG] RAW_CHUNK EOF")
            break

        text = chunk if isinstance(chunk, str) else chunk.decode("utf-8", errors="ignore")

        # ğŸ”´ ì—¬ê¸°ì„œ ì‹¤ì œ í† í° ë‹¨ìœ„ ì¶œë ¥ í™•ì¸
        logger.info(f"[DEBUG] RAW_CHUNK[{i}]: {repr(text)}")
        i += 1

        yield text


# ---------------------------
# ë¼ìš°íŠ¸
# ---------------------------
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})


# ---------------------------
# SSE STREAM
# ---------------------------
@app.get("/query/stream")
async def query_stream(question: str):

    async def event_gen():
        import asyncio

        try:
            yield "data: [STEP 0] ì§ˆë¬¸ ìˆ˜ì‹ \n\n"
            await asyncio.sleep(0)

            # STEP 1: ê²Œì´íŠ¸ (RAG / Chat íŒë‹¨)
            t0 = time.time()
            need_rag = decide_rag_needed(question)
            t1 = time.time()
            yield f"data: [STEP 1] ê²Œì´íŠ¸={need_rag} (t={t1 - t0:.2f}s)\n\n"

            # ê³µí†µ: ì§ˆì˜ í™•ì¥ì€ í•œ ë²ˆë§Œ
            expanded_text = None
            kw_list = None

            # RAG ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸
            context_a = ""
            refs_a = []
            context_b = ""
            refs_b = []

            # --- RAG or Chat ë¶„ê¸° ---
            if not need_rag:
                # ìˆœìˆ˜ Chat ëª¨ë“œ
                yield "data: [STEP 2] RAG ìŠ¤í‚µ â†’ ì¼ë°˜ ëŒ€í™” ì§„í–‰\n\n"
            else:
                yield "data: [STEP 2] í™•ì¥/ê²€ìƒ‰ ì‹œì‘ (RAG, A/B ë¹„êµ)\n\n"

                # 2-1. ì§ˆì˜ í™•ì¥ (í•œ ë²ˆë§Œ)
                expanded_text, kw_list = expand_query_kor(question)
                yield f"data: [STEP 2] í™•ì¥ í‚¤ì›Œë“œ={kw_list}\n\n"

                # ---------- A ìŠ¤íƒ ----------
                t2a = time.time()
                try:
                    hits_a = dense_retrieve_hybrid(qdr_a, emb_a, expanded_text, kw_list, COLLECTION)
                    t3a = time.time()
                    yield f"data: [STEP 3A] AìŠ¤íƒ hits={len(hits_a)} (t={t3a - t2a:.2f}s)\n\n"

                    if hits_a:
                        yield "data: [STEP 4A] AìŠ¤íƒ ë¬¸ë§¥ êµ¬ì„± ì‹œì‘\n\n"
                        context_a, refs_a = build_context(hits_a)
                    else:
                        yield "data: [STEP 3A] AìŠ¤íƒ: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n\n"
                except Exception as e:
                    yield f"data: [STEP 3A] AìŠ¤íƒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\n\n"

                # ---------- B ìŠ¤íƒ ----------
                t2b = time.time()
                try:
                    hits_b = dense_retrieve_hybrid(qdr_b, emb_b, expanded_text, kw_list, COLLECTION_B)
                    t3b = time.time()
                    yield f"data: [STEP 3B] BìŠ¤íƒ hits={len(hits_b)} (t={t3b - t2b:.2f}s)\n\n"

                    if hits_b:
                        yield "data: [STEP 4B] BìŠ¤íƒ ë¬¸ë§¥ êµ¬ì„± ì‹œì‘\n\n"
                        context_b, refs_b = build_context(hits_b)
                    else:
                        yield "data: [STEP 3B] BìŠ¤íƒ: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\n\n"
                except Exception as e:
                    yield f"data: [STEP 3B] BìŠ¤íƒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}\n\n"

            # -------- í”„ë¡¬í”„íŠ¸ ë¹Œë“œ & ìŠ¤íŠ¸ë¦¬ë° --------

            # RAGê°€ í•„ìš” ì—†ê±°ë‚˜, ë‘˜ ë‹¤ ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆìœ¼ë©´: ë‹¨ì¼ Chat ëª¨ë“œ
            if not need_rag or (not context_a and not context_b):
                sys_msg = (
                    "ë„ˆëŠ” ì¹œì ˆí•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. "
                    "ì§ˆë¬¸ì´ íŠ¹ë³„íˆ ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ìš”êµ¬í•˜ì§€ ì•ŠëŠ” í•œ, ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ë¼."
                )
                user_msg = question

                try:
                    messages = [
                        {"role": "system", "content": sys_msg},
                        {"role": "user", "content": user_msg},
                    ]
                    prompt = tokenizer.apply_chat_template(
                        messages, tokenize=False, add_generation_prompt=True
                    )
                except Exception:
                    prompt = f"<|system|>\n{sys_msg}\n<|user|>\n{user_msg}\n<|assistant|>\n"

                yield "data: [STEP 5] LLM ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (ì¼ë°˜ Chat)\n\n"

                async for chunk in triton_stream_async(prompt):
                    text = chunk if isinstance(chunk, str) else chunk.decode("utf-8", errors="ignore")
                    if text.strip():
                        yield f"data: {text}\n\n"

                yield "data: [END]\n\n"
                return

            # ì—¬ê¸°ë¶€í„°ëŠ” RAG A/B ë¹„êµ ëª¨ë“œ

            # ======================================
            # A ìŠ¤íƒ ì‘ë‹µ
            # ======================================
            if context_a:
                ref_lines_a = "\n".join(refs_a) if refs_a else "(ì¶œì²˜ ì •ë³´ ì—†ìŒ)"


                sys_msg_a = (
                    "ë‹¹ì‹ ì€ ê³¼í•™Â·ê¸°ìˆ  ë…¼ë¬¸ì„ ìš”ì•½í•´ì„œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
                    "- ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸(ë¬¸ì„œ ë°œì·Œ)ì—ì„œë§Œ ê·¼ê±°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                    "- ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ 'ì œê³µëœ ë¬¸ì„œì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë§í•˜ê³ , ì„ì˜ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\n"
                    "- í•œêµ­ì–´ ë¬¸ì¥ì—ì„œ ì •ìƒì ì¸ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•˜ê³ , ë‹¨ì–´ë“¤ì„ ê³µë°± ì—†ì´ ë¶™ì—¬ ì“°ì§€ ë§ˆì„¸ìš”.\n"
                    "- ë‹µë³€ì€ í•­ìƒ â‘  í•œ ë¬¸ë‹¨ ìš”ì•½ â‘¡ ë²ˆí˜¸ê°€ ìˆëŠ” í•µì‹¬ ì •ë¦¬ ëª©ë¡ â‘¢ 'ì°¸ê³ ë¬¸í—Œ' ì„¹ì…˜ ìˆœìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n"
                )
                user_msg_a = f"""
ë‹¤ìŒì€ [A ìŠ¤íƒ]ì—ì„œ ê²€ìƒ‰í•œ ê´€ë ¨ ë¬¸ì„œ ë°œì·Œì…ë‹ˆë‹¤. ê° ë¬¸ë‹¨ ì•ì˜ ë²ˆí˜¸ëŠ” ì¶œì²˜ ë²ˆí˜¸ì…ë‹ˆë‹¤.

[ì»¨í…ìŠ¤íŠ¸ ë°œì·Œ ì‹œì‘]
{context_a}
[ì»¨í…ìŠ¤íŠ¸ ë°œì·Œ ë]

(ì¶œì²˜ ë²ˆí˜¸ ë§¤í•‘)
{ref_lines_a}

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
{question}

ë‹µë³€ í˜•ì‹ ê°€ì´ë“œë¼ì¸(ì•„ì£¼ ì¤‘ìš”):
1. ì²« ë¬¸ë‹¨ì— 2~3ë¬¸ì¥ìœ¼ë¡œ ì „ì²´ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
2. ê·¸ ë‹¤ìŒì—ëŠ” "1. ì†Œì œëª©" í˜•ì‹ì˜ ë²ˆí˜¸ ë§¤ê¸°ê¸° ëª©ë¡ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
   - ê° í•­ëª©ì€ "1. ì†Œì œëª© [1][3]" ì²˜ëŸ¼ ê´€ë ¨ ì¶œì²˜ ë²ˆí˜¸ë¥¼ ëŒ€ê´„í˜¸ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.
   - ì†Œì œëª© ì•„ë˜ ì¤„ì—ì„œ 2~4ë¬¸ì¥ ì •ë„ë¡œ ì„¤ëª…ì„ ë§ë¶™ì…ë‹ˆë‹¤.
3. ë¬¸ì¥ ì¤‘ê°„ì— ê·¼ê±°ë¥¼ ë‹¬ ë•ŒëŠ” "â€¦ë¼ëŠ” ì ì´ ë³´ê³ ë˜ì—ˆìŠµë‹ˆë‹¤[1][3]."ì²˜ëŸ¼ [1] í˜•íƒœì˜ ì¸ìš© ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
4. í•œêµ­ì–´ ë¬¸ì¥ ì‚¬ì´ì—ëŠ” ì¼ë°˜ì ì¸ ë„ì–´ì“°ê¸°ë¥¼ ìœ ì§€í•˜ê³ ,
   'ì˜í•™ê¸°ìˆ ì˜ìµœì‹ ë™í–¥ì€'ì²˜ëŸ¼ ë‹¨ì–´ë¥¼ ëª¨ë‘ ë¶™ì—¬ ì“°ì§€ ë§ê³ 
   'ì˜í•™ ê¸°ìˆ ì˜ ìµœì‹  ë™í–¥ì€'ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
5. ë§ˆì§€ë§‰ì—ëŠ” ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

ì°¸ê³ ë¬¸í—Œ:
[1] ë…¼ë¬¸ ì œëª©A
[2] ë…¼ë¬¸ ì œëª©B
[3] ë…¼ë¬¸ ì œëª©C

ìœ„ í˜•ì‹ì„ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ ì§€í‚¤ë©´ì„œ ë‹µë³€í•˜ì„¸ìš”.
"""

                try:
                    messages_a = [
                        {"role": "system", "content": sys_msg_a},
                        {"role": "user", "content": user_msg_a},
                    ]

                    logger.info("===== [DEBUG] PROMPT_A_HEAD =====")
                    logger.info(messages_a[:400])
                    logger.info("===== [DEBUG] PROMPT_A_TAIL =====")
                    logger.info(messages_a[-400:])
                    prompt_a = tokenizer.apply_chat_template(
                        messages_a, tokenize=False, add_generation_prompt=True
                    )
                except Exception:
                    prompt_a = f"<|system|>\n{sys_msg_a}\n<|user|>\n{user_msg_a}\n<|assistant|>\n"

                yield "data: \n\n"
                yield "data: =============================\n\n"
                yield "data: [RAG-A] ì„ë² ë”©/ë²¡í„°DB ìŠ¤íƒ A ì‘ë‹µ\n\n"
                yield "data: =============================\n\n"

                async for chunk in triton_stream_async(prompt_a):
                    text = chunk if isinstance(chunk, str) else chunk.decode("utf-8", errors="ignore")
                    if text.strip():
                        yield f"data: [A] {text}\n\n"

            # ======================================
            # B ìŠ¤íƒ ì‘ë‹µ
            # ======================================
            if context_b:
                ref_lines_b = "\n".join(refs_b) if refs_b else "(ì¶œì²˜ ì •ë³´ ì—†ìŒ)"

                sys_msg_b = (
                    "ë‹¹ì‹ ì€ ê³¼í•™/ê¸°ìˆ  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” í•œêµ­ì–´ LLMì…ë‹ˆë‹¤. "
                    "ë°˜ë“œì‹œ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œë§Œ ê·¼ê±°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
                    "ì´ ì‘ë‹µì€ [B ìŠ¤íƒ] ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤."
                )
                user_msg_b = f"""
ë‹¤ìŒì€ [B ìŠ¤íƒ]ì—ì„œ ê²€ìƒ‰í•œ ê´€ë ¨ ë¬¸ì„œ ë°œì·Œì…ë‹ˆë‹¤(ë²ˆí˜¸=ì¶œì²˜):
{context_b}

(ì¶œì²˜ ë²ˆí˜¸ ë§¤í•‘)
{ref_lines_b}

ì§ˆë¬¸: {question}

ìš”êµ¬ì‚¬í•­:
- ë¬¸ì¥ ë‚´ì— [1], [2] í˜•íƒœë¡œ ê·¼ê±° ë²ˆí˜¸ë¥¼ ë‹¬ì•„ì£¼ì„¸ìš”.
- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì“°ì§€ ë§ˆì„¸ìš”(ì¶”ê°€ ì§€ì‹ ê¸ˆì§€).
- ë§ˆì§€ë§‰ ì¤„ì— 'ì°¸ê³ ë¬¸í—Œ:' ë’¤ì— ë…¼ë¬¸ ì œëª©ì„ í•¨ê»˜ ë‚˜ì—´í•˜ì„¸ìš”. ì˜ˆì‹œ: ì°¸ê³ ë¬¸í—Œ: [1] ì œëª©A, [2] ì œëª©B
"""

                try:
                    messages_b = [
                        {"role": "system", "content": sys_msg_b},
                        {"role": "user", "content": user_msg_b},
                    ]

                    logger.info("===== [DEBUG] PROMPT_B_HEAD =====")
                    logger.info(messages_b[:400])
                    logger.info("===== [DEBUG] PROMPT_B_TAIL =====")
                    logger.info(messages_b[-400:])
                    prompt_b = tokenizer.apply_chat_template(
                        messages_b, tokenize=False, add_generation_prompt=True
                    )
                except Exception:
                    prompt_b = f"<|system|>\n{sys_msg_b}\n<|user|>\n{user_msg_b}\n<|assistant|>\n"

                yield "data: \n\n"
                yield "data: =============================\n\n"
                yield "data: [RAG-B] ì„ë² ë”©/ë²¡í„°DB ìŠ¤íƒ B ì‘ë‹µ\n\n"
                yield "data: =============================\n\n"

                async for chunk in triton_stream_async(prompt_b):
                    text = chunk if isinstance(chunk, str) else chunk.decode("utf-8", errors="ignore")
                    if text.strip():
                        yield f"data: [B] {text}\n\n"

            # ìµœì¢… ì¢…ë£Œ
            yield "data: [END]\n\n"

        except Exception as e:
            err = f"{type(e).__name__}: {e}"
            traceback.print_exc()
            yield f"data: âš ï¸ ì˜¤ë¥˜: {err}\n\n"
            yield "data: [END]\n\n"

    return StreamingResponse(
        event_gen(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
            "Connection": "keep-alive",
            "Transfer-Encoding": "chunked",
        },
    )


# ---------------------------
# ë¡œì»¬ ì‹¤í–‰
# ---------------------------
if __name__ == "__main__":
    import uvicorn

    # ìš´ì˜ì—ì„œëŠ” --workers 1 ê¶Œì¥ (ì „ì—­ ì»¤ë„¥ì…˜ ì¬ì‚¬ìš© ë° ë””ë²„ê¹… í¸ì˜)
    uvicorn.run(app, host="0.0.0.0", port=8082, reload=False)
